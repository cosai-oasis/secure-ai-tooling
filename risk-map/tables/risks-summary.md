| ID   | Title                         | Description                                                                                                                                                                                             | Category                         |
|:-----|:------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------|
| DMS  | Denial of ML Service          | Overloading ML systems with resource-intensive queries. Like traditional DoS attacks, Denial of ML Service can reduce availability of or entirely disrupt a service.<br>                                | risksRuntimeInputSecurity        |
| DP   | Data Poisoning                | Altering data sources used to train the model. In terms of impact, Data Poisoning is comparable to modifying the logic of an application to change its behavior.<br>                                    | risksSupplyChainAndDevelopment   |
| EDH  | Excessive Data Handling       | Unauthorized collection, retention, processing, or sharing of user data. Excessive Data Handling may lead to policy and legal challenges.<br>                                                           | risksSupplyChainAndDevelopment   |
| IIC  | Insecure Integrated Component | Software vulnerabilities that can be leveraged to compromise AI models. Insecure Integrated Component can lead to privacy and security concerns, as well as potential ethical and legal challenges.<br> | risksDeploymentAndInfrastructure |
| IMO  | Insecure Model Output         | Unvalidated model output passed to the end user. Insecure Model Output poses risks to organizational reputation, security, and user safety.<br>                                                         | risksRuntimeOutputSecurity       |
| ISD  | Inferred Sensitive Data       | Model inferring personal information not contained in training data or inputs. Inferred Sensitive Data may be considered a data privacy incident.<br>                                                   | risksRuntimeDataSecurity         |
| MDT  | Model Deployment Tampering    | Unauthorized changes to model deployment components. Model Deployment Tampering can result in changes to model behavior.<br>                                                                            | risksDeploymentAndInfrastructure |
| MEV  | Model Evasion                 | Changes to a prompt input to cause the model to produce incorrect inferences. Model Evasion can lead to reputational, legal, security, and privacy risks.<br>                                           | risksRuntimeInputSecurity        |
| MRE  | Model Reverse Engineering     | Recreating a model by analyzing its inputs, outputs, and behaviors. A reverse engineer model can be used to create imitation products or adversarial attacks.<br>                                       | risksDeploymentAndInfrastructure |
| MST  | Model Source Tampering        | Tampering with the model's code or data. Model Source Tampering is similar to tampering with traditional software code, and can create vulnerabilities or unintended behavior.<br>                      | risksSupplyChainAndDevelopment   |
| MXF  | Model Exfiltration            | Theft of a model. Similar to stealing code, this threat has both intellectual property and security implications.<br>                                                                                   | risksDeploymentAndInfrastructure |
| PIJ  | Prompt Injection              | Tricking a model to run unintended commands. In terms of impact, Prompt Injection can change a model's behavior.<br>                                                                                    | risksRuntimeInputSecurity        |
| RA   | Rogue Actions                 | Unintentional model-based actions executed via extensions. Rogue Actions can create a cascading, risk to organizational reputation, user trust, security, and safety.<br>                               | risksRuntimeOutputSecurity       |
| SDD  | Sensitive Data Disclosure     | Disclosure of sensitive data by the model. Sensitive Data Disclosure poses a threat to user privacy, organizational reputation, and intellectual property.<br>                                          | risksRuntimeDataSecurity         |
| UTD  | Unauthorized Training Data    | Using unauthorized data for model training. Using a model trained with Unauthorized Training Data might lead to legal or ethical challenges.<br>                                                        | risksSupplyChainAndDevelopment   |