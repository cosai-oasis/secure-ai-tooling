# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

id: components
title: CoSAI Risk Map components
description:
  - 'The CoSAI Risk Map categorizes AI development into four areas:'
  - - Data
    - Infrastructure
    - Model
    - Application
  - >
    This framing represents the broadened scope of AI development compared to traditional
    software development. In addition to the familiar code, infrastructure, and application
    components, AI introduces the complexities of data, training, and model development.
    Understanding how these dimensions work together is crucial to assessing the unique
    risks of AI development. The controls suggested to address the risks across this
    framing all align with the six core elements of Google's SAIF.
categories:
  - id: componentsInfrastructure
    title: Infrastructure components
    description:
      - >
        The data components of AI development depend on the infrastructure underpinning
        with secure hardware, resilient code, data storage, and development and deployment
        platforms. Risks to this infrastructure can affect model and framework code,
        model and data storage, and model serving.
      - >
        Attackers could try to poison, manipulate, or steal the data, models, or weights
        held in storage. If the model source code, dependencies, or any tools used
        to create and deploy them aren’t protected, attackers could tamper with them
        to create drastic changes to the model’s behavior, causing major security issues.
      - >
        The first step in securing these infrastructure components is to apply traditional
        security practices to the physical environments used for training, storage
        and serving. Host and network security is needed to restrict potential attackers.
        Authentication and authorization for any access to the physical environments
        is essential. Software supply chain integrity for all traditional software
        dependencies should be considered.
    subcategory:
      - id: componentsData
        title: Data components
        description:
          - >
            Traditional software development follows predictable instructions: the user
            inputs trigger static code, which determines the logic driving outcomes of the
            program. In AI development, data takes on aspects of the role previously played
            by code—which transforms the security and privacy risks.
          - >
            AI models are dynamic systems. They rely not only on their static code and user
            inputs, but also on learned patterns encoded in their internal parameters, referred
            to as 'model weights.' These weights are derived from the model's training
            data and training processes.
          - >
            Compromising these model weights can have a significant impact on the model's
            behavior and outputs. This makes attacks on model weights as potentially damaging
            as attacks targeting the code in traditional software development.
  - id: componentsModel
    title: Model components
    description:
      - >
        The central concept for AI-powered applications is the model. The purpose of
        a model is to apply the  statistical patterns extracted from training data
        and use these to generate new text, images, videos, or other output data (also
        known as inferences) from input data provided to it.
    subcategory:
      - id: componentsModelTraining
        title: Model training components
        description:
          - >
            Primary processes and artifacts leveraged in the training of models from source data
            and algorithms.
      - id: componentsOrchestration
        title: Orchestration
        description:
          - >
            Beyond its core reasoning and planning capabilities, an agent relies on a 
            variety of external components to access information, process data, and 
            execute actions. This process is called orchestration because it involves 
            managing and coordinating a variety of independent services and data sources 
            to achieve a single, complex task. These resources provide the agent with its 
            memory, its ability to act in the physical world, and the specific knowledge 
            needed to complete taste. Securing these external components is critical, 
            since they represent key interaction points that can be targeted by attackers 
            to manipulate the agent’s behavior.
  - id: componentsApplication
    title: Application components
    description:
      - >
        Users interact with AI models differently than with traditional algorithm-based
        searches and services. Some AI models act in response to more natural user
        prompting, with wording and phrasing choices directly affecting how an LLM,
        for example, infers requests, actions, and intent. When compared to interactions
        processed through an API, this more direct interaction introduces new avenues
        of risk, such as prompt injection.
      - >
        Additionally, Generative AI models are increasingly used as agents or assistants
        that can act on a user’s behalf to provide helpful functions. In these situations,
        AI models are interacting with other systems to get information or run specialized
        computational functions, including state-changing actions. While this networking
        opens up exciting possibilities of more complex behaviors, each connection
        also increases the potential impact of a successful attack on the AI model
        or network.
    subcategory:
      - id: componentsAgent
        title: Agent components
        description:
          - >
            Agentic systems differ from other AI systems in their ability to take autonomous actions.
components:
  - id: componentDataSources
    title: Data Sources
    description:
      - >
        The original sources or repositories from which data is gathered for potential
        use in training an AI model. These can include databases, APIs, web scraping,
        or even sensor data. The quality and diversity of data sources significantly
        impact the model's capabilities.
    category: componentsInfrastructure
    subcategory: componentsData
    edges:
      to:
        - componentDataFilteringAndProcessing
      from: []
  - id: componentDataFilteringAndProcessing
    title: Data Filtering and Processing
    description:
      - >
        The processes of cleaning, transforming, and preparing raw data from various
        sources to make it suitable for training. This may include labeling data, removing
        duplicates or errors, and even generating new synthetic data to enhance the
        model's learning.
    category: componentsInfrastructure
    subcategory: componentsData
    edges:
      to:
        - componentTrainingData
      from:
        - componentDataSources
  - id: componentTrainingData
    title: Training Data
    description:
      - >
        The final, curated subset of data that is fed into the AI model during the training
        process. This data is used to adjust the model's internal parameters, enabling
        it to learn patterns and make predictions or inferences.
    category: componentsInfrastructure
    subcategory: componentsData
    edges:
      to:
        - componentDataStorage
      from:
        - componentDataFilteringAndProcessing
  - id: componentDataStorage
    title: Data Storage Infrastructure
    description:
      - >
        Storage for training data. Training data is stored from ingestion through filtering
        and usage during training.
    category: componentsInfrastructure
    edges:
      to:
        - componentModelTrainingTuning
      from:
        - componentTrainingData
  - id: componentModelFrameworksAndCode
    title: Model Frameworks and Code
    description:
      - >
        The code and frameworks necessary to train and use a model. Model code defines
        the model architecture and number and types of layers in the model. Framework
        code implements the steps for each layer to train and evaluate the model. The
        framework code is generally necessary not just for training a model, but also
        required to run inferences (i.e., make predictions) when the model is in use.
        Usually framework code is shipped separately from the model itself and needs
        to be installed to use the model.
    category: componentsModel
    subcategory: componentsModelTraining
    edges:
      to:
        - componentModelTrainingTuning
  - id: componentModelEvaluation
    title: Model Evaluation
    description:
      - >
        The process of testing the model against new data to see how well it performs (evaluation). 
        Evaluation happens in two stages: during the training
        process, when each checkpointed update to the model is evaluated, and after
        the model is trained, to assess how well it performs at its intended purpose.
    category: componentsModel
    subcategory: componentsModelTraining
    edges:
      to:
        - componentModelTrainingTuning
      from:
        - componentTheModel
  - id: componentModelTrainingTuning
    title: Training and Tuning
    description:
      - >
        The process of teaching a model to extract the correct patterns and inferences
        from data by adjusting the probability of a given outcome (training) and adjusting
        a smaller set of probabilities to tune a model to a specific task (tuning).
        Given the enormous cost of training, many model creators take a preexisting
        model and tune it to their needs, by focusing only on the training related
        to a specific type of task.
    category: componentsModel
    subcategory: componentsModelTraining
    edges:
      to:
        - componentTheModel
      from:
        - componentModelEvaluation
        - componentModelFrameworksAndCode
        - componentDataStorage
  - id: componentModelStorage
    title: Model Storage
    description:
      - >
        Storage for the model. Model storage refers to multiple stages in the development process:
        - >
          local storage during training, in which each checkpoint is stored until overwritten;
        - >
          published storage, after training is completed and the model is uploaded
          to a model hub (a centralized model repository).
      - >
        Note: Many model consumers use remote models served by API. Those model consumers
        that store models themselves, though, should consider the same Model Storage
        risks that apply to model creators.
    category: componentsInfrastructure
    edges:
      to:
        - componentTheModel
  - id: componentModelServing
    title: Model Serving Infrastructure
    description:
      - >
        The systems and process to deploy a model in production, making them available
        for services and applications.
      - >
        Note: Many model consumers use remote models served via API. Those that serve
        their own models, though, should consider the same Model Serving risks that
        apply to model creators.
    category: componentsInfrastructure
    edges:
      to:
        - componentTheModel
  - id: componentTheModel
    title: The Model
    description:
      - >
        A pairing of code and weights, created with data during a training process.
        In the CoSAI Risk Map, the model is represented as the result of the output
        of the Data Components being trained, stored, and served using the Infrastructure
        Components. A model is ultimately useful when deployed in applications, using
        Application Components.
    category: componentsModel
    edges:
      to:
        - componentModelEvaluation
        - componentAgentInputHandling
        - componentApplicationInputHandling
        - componentOrchestrationInputHandling
      from:
        - componentModelTrainingTuning
        - componentModelServing
        - componentModelStorage
        - componentAgentOutputHandling
        - componentApplicationOutputHandling
        - componentOrchestrationOutputHandling
  - id: componentApplication
    title: Application
    description:
      - >
        The application, product, or feature that uses an AI model for functionality.
        These applications might be directly user-facing, as in the case of a customer
        service chatbot, or the “user” might be a service within an organization,
        querying the model to power an upstream process. If an application has the
        ability to execute tools on behalf of its user, it is sometimes referred to
        as an Agent.
    category: componentsApplication
    edges:
      to:
        - componentApplicationOutputHandling
        - componentAgentInputHandling
      from:
        - componentApplicationInputHandling
        - componentAgentOutputHandling
  - id: componentApplicationOutputHandling
    title: Output Handling
    description:
      - >
        Input handling components filter, sanitize, and protect against potentially
        malicious inputs, whether from a user or more generally from anything outside
        the trusted system. Input handling acts as a control against numerous risks
        and is an area ripe for more research and development.
    category: componentsApplication
    edges:
      to:
        - componentTheModel
      from:
        - componentApplication
  - id: componentApplicationInputHandling
    title: Input Handling
    description:
      - >
        Similar to input handling, output handling components filter, sanitize, and
        protect against unwanted, unexpected or dangerous outputs from a model. Output
        handling is a major line of defense against various risks and an area primed
        for more development.
    category: componentsApplication
    edges:
      to:
        - componentApplication
      from:
        - componentTheModel
  - id: componentReasoningCore
    title: Agent Reasoning Core
    description:
      - >
        The core of an agent’s functionality is its ability to reason about a user’s goal
        and create a plan to achieve it. The reasoning core processes system instructions,
        user queries, and contextual information to generate a sequence of actions. The 
        actions, or tool calls, allow the agent to affect the real world—interacting with 
        external systems, retrieving new information, or making changes to data and resources.

        The reasoning core typically consists of one or more models—possibly separate 
        models for the reasoning and then planning steps, or potentially one large model 
        able to do both. The process of planning is often iterative, taking place in a 
        “reasoning loop” where the plan is refined based on new information or the results 
        of previous actions. This iterative nature, combined with the ingestion of 
        external data, creates a vulnerability to indirect prompt injection, where 
        adversarially crafted information can manipulate the agent's planning process.

        The complexity of plans determines the agent’s level of autonomy, which can 
        range from selecting a predefined workflow to dynamically orchestrating 
        multi-step actions. This level of autonomy directly governs the potential 
        severity of a security failure—the more an agent can do on its own, the greater 
        the risk from manipulation or misalignment, if the agent's actions do not have 
        guardrails.
    category: componentsApplication
    subcategory: componentsAgent
    edges:
      to:
        - componentAgentOutputHandling
        - componentOrchestrationInputHandling
      from:
        - componentAgentInputHandling
        - componentOrchestrationOutputHandling
  - id: componentOrchestrationOutputHandling
    title: Output Handling
    description:
      - >
        Orchestration output is responsible for validating, sanitizing, and safely 
        formatting data as it exits the system to external or downstream components. 
        This control ensures outbound data meets defined schemas, strips sensitive 
        information that shouldn't be exposed, prevents injection attacks by properly 
        encoding outputs for their destination context (such as HTML encoding for 
        web responses or parameterization for database queries), and enforces 
        data classification policies.
    category: componentsModel
    subcategory: componentsOrchestration
    edges:
      to:
        - componentReasoningCore
        - componentTheModel
      from:
        - componentTools
        - componentMemory
        - componentRAGContent
  - id: componentOrchestrationInputHandling
    title: Input Handling
    description:
      - >
        Orchestration input handling  is responsible for validating, sanitizing, and 
        normalizing all data entering the system from external sources before it 
        reaches core orchestration logic.
    category: componentsModel
    subcategory: componentsOrchestration
    edges:
      to:
        - componentTools
        - componentMemory
        - componentRAGContent
      from:
        - componentTheModel
        - componentReasoningCore
  - id: componentTools
    title: External Tools and Services
    description:
      - >
        Tools are the external APIs and services an agent uses to take action in the 
        world, which must be secured with least-privilege permissions. A key risk comes 
        from deceptive descriptions on third-party tools, which can trick the agent into 
        performing unintended, harmful functions.
    category: componentsModel
    subcategory: componentsOrchestration
    edges:
      to:
        - componentOrchestrationOutputHandling
      from:
        - componentOrchestrationInputHandling
  - id: componentMemory
    title: Model Memory
    description:
      - >
        Memory allows a model or agent to retain context and learn facts across interactions. 
        It becomes a security risk if malicious data is stored, leading to persistent 
        attacks, or if memory isn't properly isolated between different users.
    category: componentsModel
    subcategory: componentsOrchestration
    edges:
      to:
        - componentOrchestrationOutputHandling
      from:
        - componentOrchestrationInputHandling
  - id: componentRAGContent
    title: Retrieval Augmented Generation & Content
    description:
      - >
        Content for Retrieval-Augmented Generation (RAG) provides the agent with curated 
        knowledge to ground its responses and improve accuracy. The main security risk is 
        data poisoning, where an attacker corrupts this knowledge source to manipulate the 
        agent's output.
    category: componentsModel
    subcategory: componentsOrchestration
    edges:
      to:
        - componentOrchestrationOutputHandling
      from:
        - componentOrchestrationInputHandling
  - id: componentAgentUserQuery
    title: Agent User Query
    description:
      - >
        These contain the specific details of a user’s request after being processed. The 
        query is then combined with system instructions and other contextual data, like 
        agent memory or external information, to create a single, structured prompt for 
        the reasoning core to process.
    category: componentsApplication
    subcategory: componentsAgent
    edges:
      to:
        - componentAgentInputHandling
      from: []
  - id: componentAgentSystemInstruction
    title: Agent System Instructions
    description:
      - >
        These define an agent’s capabilities, permissions, and limitations, such as the 
        actions it can take and the tools it is allowed to use. For security, it’s 
        critical to unambiguously separate these instructions from user data and other 
        inputs, often using special control tokens to prevent prompt injection attacks.
    category: componentsApplication
    subcategory: componentsAgent
    edges:
      to:
        - componentAgentInputHandling
      from: []
  - id: componentAgentInputHandling
    title: Input Handling
    description:
      - >
        An agent’s interaction with the world begins at the User or Application, which 
        serves as the interface for collecting both explicit user instructions and passively 
        collected contextual data from its environment. This blend of inputs creates a 
        primary security challenge of reliably distinguishing trusted commands from the 
        controlling user versus potentially untrusted information from other sources. 
        An agent application processes explicit user instructions, which can be given 
        directly (synchronously) like a typed command, or be configured to execute 
        automatically when a specific event occurs (asynchronously). It also gathers 
        implicit contextual inputs—data that isn’t a direct command but is passively 
        collected from the environment, such sensor readings, application state, or the 
        content of recently opened documents.

        Input Handling is is responsible for processing and understanding these inputs 
        before they are sent to the agent’s reasoning core. This handoff is a critical 
        security juncture, as the perception layer must reliably distinguish trusted user 
        commands from untrusted data to prevent manipulation of the agent’s core logic.
    category: componentsApplication
    subcategory: componentsAgent
    edges:
      to:
        - componentReasoningCore
      from:
        - componentAgentUserQuery
        - componentAgentSystemInstruction
        - componentTheModel
        - componentApplication
  - id: componentAgentOutputHandling
    title: Output Handling
    description:
      - >
        The final step in an agent’s workflow is response rendering, the process or 
        formatting of an AI agent’s generated output for display and interaction within a 
        user application. This stage is a critical security boundary because it involves 
        taking dynamic content from the agent and displaying it within the trusted context 
        of a user’s application, such as a web browser or mobile application. Flaws in 
        this process can allow malicious content generated by a compromised agent to be 
        executed by the application, leading to significant security breaches.

        Agents often produce content in a universal format like Markdown, which is then 
        interpreted and rendered by the specific client application. If this output isn’t 
        properly sanitized according to the content type, it can create severe 
        vulnerabilities. For example, unsanitized output can lead to attacks like data 
        exfiltration or even cross-site scripting (XSS).
    category: componentsApplication
    subcategory: componentsAgent
    edges:
      to:
        - componentApplication
        - componentTheModel
      from:
        - componentReasoningCore
